{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gZDkaKG23TMt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import urlparse, parse_qs, urlencode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iaKccSVz3eDF"
      },
      "outputs": [],
      "source": [
        "# Insert DHIS2 username and password\n",
        "DHIS2_USERNAME = \"kamutis\"\n",
        "DHIS2_PASSWORD = \"Laptop2012\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e8Id6_uV3sja"
      },
      "outputs": [],
      "source": [
        "original_url = \"https://hiskenya.org/api/analytics.csv?dimension=pe%3A2013%3B2014%3B2015%3B2016%3B2017%3B2018%3B2019%3B2020%3B2021%3B2022%3B2023%3B2024&dimension=ou%3AHfVjCurKxh2%3BUSER_ORGUNIT%3BLEVEL-JwTgQwgnl8h&dimension=dx%3ANLKRV7bYbVy%3Bw5ltvnNihEZ%3BMpv8crmnOzy%3BdRhugDCanvB%3BEaR7DO0Fz9g%3BG5AHuOAotQq%3BbPQDV3mud0v%3Bpct05jgGcLt%3BwLbBr9Vsvwo%3Ba73BxXAmC08&tableLayout=true&rows=pe%3Bou%3Bdx&skipRounding=false&completedOnly=false&showHierarchy=true\"\n",
        "\n",
        "parsed_url = urlparse(original_url)\n",
        "base_url = parsed_url.scheme + \"://\" + parsed_url.netloc + parsed_url.path\n",
        "query_params = parse_qs(parsed_url.query)\n",
        "\n",
        "# Convert query_params values from lists to single strings for easier manipulation,\n",
        "# especially for 'dimension' which can have multiple instances.\n",
        "# We'll re-handle 'dimension' specifically later.\n",
        "cleaned_params = {k: v[0] if len(v) == 1 else v for k, v in query_params.items()}\n",
        "\n",
        "# Extract existing 'dimension' parameters, excluding the 'pe' one for now\n",
        "other_dimensions = [d for d in cleaned_params.get('dimension', []) if not d.startswith('pe:')]\n",
        "if not isinstance(other_dimensions, list): # handle case where there was only one dimension originally\n",
        "    other_dimensions = [other_dimensions] if 'dimension' in cleaned_params else []\n",
        "\n",
        "# Remove 'pe' dimension if it exists\n",
        "if 'dimension' in cleaned_params:\n",
        "    if isinstance(cleaned_params['dimension'], list):\n",
        "        cleaned_params['dimension'] = [d for d in cleaned_params['dimension'] if not d.startswith('pe:')]\n",
        "    else: # single dimension string\n",
        "        if cleaned_params['dimension'].startswith('pe:'):\n",
        "            del cleaned_params['dimension']\n",
        "\n",
        "# Clean up other parameters that are not 'dimension'\n",
        "final_params = {k: v for k, v in cleaned_params.items() if k != 'dimension'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOLyWeAA30EB",
        "outputId": "047c8f76-51f9-4b98-b27f-8c22ba8dbd52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated period dimension: pe:201301;201302;201303;201304;201305;201306;201307;201308;201309;201310;201311;201312;201401;201402;201403;201404;201405;201406;201407;201408;201409;201410;201411;201412;201501;201502;201503;201504;201505;201506;201507;201508;201509;201510;201511;201512;201601;201602;201603;201604;201605;201606;201607;201608;201609;201610;201611;201612;201701;201702;201703;201704;201705;201706;201707;201708;201709;201710;201711;201712;201801;201802;201803;201804;201805;201806;201807;201808;201809;201810;201811;201812;201901;201902;201903;201904;201905;201906;201907;201908;201909;201910;201911;201912;202001;202002;202003;202004;202005;202006;202007;202008;202009;202010;202011;202012;202101;202102;202103;202104;202105;202106;202107;202108;202109;202110;202111;202112;202201;202202;202203;202204;202205;202206;202207;202208;202209;202210;202211;202212;202301;202302;202303;202304;202305;202306;202307;202308;202309;202310;202311;202312;202401;202402;202403;202404;202405;202406;202407;202408;202409;202410;202411;202412\n",
            "\n",
            "Full Request URL:\n",
            "https://hiskenya.org/api/analytics.csv?tableLayout=true&rows=pe%3Bou%3Bdx&skipRounding=false&completedOnly=false&showHierarchy=true&dimension=pe%3A201301%3B201302%3B201303%3B201304%3B201305%3B201306%3B201307%3B201308%3B201309%3B201310%3B201311%3B201312%3B201401%3B201402%3B201403%3B201404%3B201405%3B201406%3B201407%3B201408%3B201409%3B201410%3B201411%3B201412%3B201501%3B201502%3B201503%3B201504%3B201505%3B201506%3B201507%3B201508%3B201509%3B201510%3B201511%3B201512%3B201601%3B201602%3B201603%3B201604%3B201605%3B201606%3B201607%3B201608%3B201609%3B201610%3B201611%3B201612%3B201701%3B201702%3B201703%3B201704%3B201705%3B201706%3B201707%3B201708%3B201709%3B201710%3B201711%3B201712%3B201801%3B201802%3B201803%3B201804%3B201805%3B201806%3B201807%3B201808%3B201809%3B201810%3B201811%3B201812%3B201901%3B201902%3B201903%3B201904%3B201905%3B201906%3B201907%3B201908%3B201909%3B201910%3B201911%3B201912%3B202001%3B202002%3B202003%3B202004%3B202005%3B202006%3B202007%3B202008%3B202009%3B202010%3B202011%3B202012%3B202101%3B202102%3B202103%3B202104%3B202105%3B202106%3B202107%3B202108%3B202109%3B202110%3B202111%3B202112%3B202201%3B202202%3B202203%3B202204%3B202205%3B202206%3B202207%3B202208%3B202209%3B202210%3B202211%3B202212%3B202301%3B202302%3B202303%3B202304%3B202305%3B202306%3B202307%3B202308%3B202309%3B202310%3B202311%3B202312%3B202401%3B202402%3B202403%3B202404%3B202405%3B202406%3B202407%3B202408%3B202409%3B202410%3B202411%3B202412&dimension=ou%3AHfVjCurKxh2%3BUSER_ORGUNIT%3BLEVEL-JwTgQwgnl8h&dimension=dx%3ANLKRV7bYbVy%3Bw5ltvnNihEZ%3BMpv8crmnOzy%3BdRhugDCanvB%3BEaR7DO0Fz9g%3BG5AHuOAotQq%3BbPQDV3mud0v%3Bpct05jgGcLt%3BwLbBr9Vsvwo%3Ba73BxXAmC08\n",
            "\n",
            "Data fetched successfully!\n",
            "\n",
            "First 5 rows of the DataFrame:\n",
            "   periodid  periodname  periodcode  perioddescription orgunitlevel1  \\\n",
            "0    201404  April 2014      201404                NaN         Kenya   \n",
            "1    201404  April 2014      201404                NaN         Kenya   \n",
            "2    201404  April 2014      201404                NaN         Kenya   \n",
            "3    201404  April 2014      201404                NaN         Kenya   \n",
            "4    201404  April 2014      201404                NaN         Kenya   \n",
            "\n",
            "         orgunitlevel2 organisationunitid organisationunitname  \\\n",
            "0       Turkana County        kphDeKClFch       Turkana County   \n",
            "1  Taita Taveta County        QyGNX2DpR4h  Taita Taveta County   \n",
            "2        Migori County        fVra3Pwta0Q        Migori County   \n",
            "3     Nyandarua County        mYZacFNIB3h     Nyandarua County   \n",
            "4      Kakamega County        BjC1xL40gHo      Kakamega County   \n",
            "\n",
            "  organisationunitcode  organisationunitdescription       dataid  \\\n",
            "0         KE_County_23                          NaN  w5ltvnNihEZ   \n",
            "1          KE_County_6                          NaN  NLKRV7bYbVy   \n",
            "2         KE_County_44                          NaN  Mpv8crmnOzy   \n",
            "3         KE_County_18                          NaN  pct05jgGcLt   \n",
            "4         KE_County_37                          NaN  wLbBr9Vsvwo   \n",
            "\n",
            "                             dataname  datacode  datadescription      Total  \n",
            "0                   Population female       NaN              NaN  476118.00  \n",
            "1                    Total Population       NaN              NaN  310244.00  \n",
            "2                     Population male       NaN              NaN  523839.00  \n",
            "3  Estimated Number of Pregnant Women       NaN              NaN   18732.00  \n",
            "4              Population Growth Rate       NaN              NaN       2.62  \n",
            "\n",
            "DataFrame shape: (49488, 15)\n"
          ]
        }
      ],
      "source": [
        "# Add the new period dimension and the other existing dimensions\n",
        "final_params_list = []\n",
        "for k, v in final_params.items():\n",
        "    if isinstance(v, list):\n",
        "        for item in v:\n",
        "            final_params_list.append((k, item))\n",
        "    else:\n",
        "        final_params_list.append((k, v))\n",
        "\n",
        "# Define the period dimension value - using 'pe:202501' from the original URL\n",
        "start_date = datetime(2013, 1, 1) # CHANGED THIS LINE TO START IN JANUARY 2019\n",
        "end_date = datetime(2024, 12, 31)\n",
        "\n",
        "periods = []\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    periods.append(current_date.strftime(\"%Y%m\"))\n",
        "    # Move to the next month\n",
        "    if current_date.month == 12:\n",
        "        current_date = datetime(current_date.year + 1, 1, 1)\n",
        "    else:\n",
        "        current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
        "\n",
        "period_dimension_value = \"pe:\" + \";\".join(periods)\n",
        "print(f\"Generated period dimension: {period_dimension_value}\")\n",
        "\n",
        "# Add the specific dimension for periods\n",
        "final_params_list.append(('dimension', period_dimension_value))\n",
        "\n",
        "# Add the other original dimensions (dx, ou, etc.)\n",
        "for dim in other_dimensions:\n",
        "    final_params_list.append(('dimension', dim))\n",
        "\n",
        "# Re-encode the query parameters\n",
        "new_query_string = urlencode(final_params_list, doseq=True) # doseq=True handles multiple 'dimension' keys\n",
        "\n",
        "full_request_url = f\"{base_url}?{new_query_string}\"\n",
        "print(f\"\\nFull Request URL:\\n{full_request_url}\\n\")\n",
        "\n",
        "try:\n",
        "    response = requests.get(full_request_url, auth=(DHIS2_USERNAME, DHIS2_PASSWORD))\n",
        "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "    # Read the content into a pandas DataFrame\n",
        "    data_df = pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "    print(\"Data fetched successfully!\")\n",
        "    print(\"\\nFirst 5 rows of the DataFrame:\")\n",
        "    print(data_df.head())\n",
        "\n",
        "    print(f\"\\nDataFrame shape: {data_df.shape}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as err:\n",
        "    print(f\"HTTP error occurred: {err}\")\n",
        "    print(f\"Response Content:\\n{response.text}\")\n",
        "except requests.exceptions.ConnectionError as err:\n",
        "    print(f\"Connection error occurred: {err}\")\n",
        "except requests.exceptions.Timeout as err:\n",
        "    print(f\"Timeout error occurred: {err}\")\n",
        "except requests.exceptions.RequestException as err:\n",
        "    print(f\"An unexpected error occurred: {err}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5hqcoTP_4LKz",
        "outputId": "d605c5e8-1102-4b7c-bc74-051f63467568"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-78708ce5712b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_qs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;31m# Import the files module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import urlparse, parse_qs, urlencode\n",
        "from google.colab import files # Import the files module\n",
        "\n",
        "\n",
        "# --- Section to save and download the data ---\n",
        "if 'data_df' in locals() and not data_df.empty:\n",
        "    # Define the filename to be saved in Colab's temporary storage\n",
        "    # This file will then be downloaded to your local machine\n",
        "    output_filename = \"ke_population_data.csv\"\n",
        "\n",
        "    # Save the DataFrame to a CSV file within Colab's temporary environment\n",
        "    data_df.to_csv(output_filename, index=False)\n",
        "    print(f\"\\nData saved to Colab's temporary storage: /{output_filename}\")\n",
        "\n",
        "    # Trigger the download to your local machine\n",
        "    files.download(output_filename)\n",
        "    print(f\"'{output_filename}' has been downloaded to your local machine's default downloads folder.\")\n",
        "    print(\"Please move it manually from there to <\\\\your local working directory>\")\n",
        "\n",
        "\n",
        "    # To display info about the DataFrame columns and types\n",
        "    print(\"\\nDataFrame Info:\")\n",
        "    data_df.info()\n",
        "else:\n",
        "    print(\"\\nNo data to save or download (DataFrame is empty or not created).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "EBWHDIgG4bin",
        "outputId": "b3d973d6-ab8e-4472-ca43-3939d4422bc3"
      },
      "outputs": [],
      "source": [
        "data_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyIT-FNb4lpl",
        "outputId": "09135229-8b8a-469e-dc85-ca3b3bb79bf8"
      },
      "outputs": [],
      "source": [
        "if 'data_df' in locals() and isinstance(data_df, pd.DataFrame):\n",
        "    num_rows = data_df.shape[0]\n",
        "    num_cols = data_df.shape[1]\n",
        "    print(f\"\\nThe DataFrame has {num_rows} rows and {num_cols} columns.\")\n",
        "else:\n",
        "    print(\"\\n'data_df' is not available or is not a pandas DataFrame. Please ensure the data fetching step was successful.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbZvI4kQcFeK",
        "outputId": "559fb471-c393-4b82-a675-9696cee385c4"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# class FPDataAnalyzer:\n",
        "#     \"\"\"\n",
        "#     A class to analyze family planning stock data from a single row (or dictionary).\n",
        "\n",
        "#     This class computes various stock metrics (losses, dispensed, at hand, requested, received)\n",
        "#     for different family planning methods based on predefined column name patterns.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, data_row):\n",
        "#         \"\"\"\n",
        "#         Initializes the FPDataAnalyzer with a single row of data.\n",
        "\n",
        "#         Args:\n",
        "#             data_row (dict or pandas.Series): A dictionary or pandas Series\n",
        "#                                               containing the column data for a single record.\n",
        "#         \"\"\"\n",
        "#         self.data = data_row\n",
        "\n",
        "#     def _get_metric(self, method_prefix, metric_suffix):\n",
        "#         \"\"\"\n",
        "#         Helper method to safely retrieve a metric value.\n",
        "\n",
        "#         Args:\n",
        "#             method_prefix (str): The prefix for the FP method (e.g., \"Combined oral contraceptive Pills\").\n",
        "#             metric_suffix (str): The suffix for the specific metric (e.g., \"Losses\").\n",
        "\n",
        "#         Returns:\n",
        "#             float or int: The value of the metric, or 0 if the column is missing or value is not numeric.\n",
        "#         \"\"\"\n",
        "#         column_name = f\"{method_prefix} {metric_suffix}\"\n",
        "#         try:\n",
        "#             # Attempt to convert to numeric, coercing errors to NaN, then fill with 0\n",
        "#             value = pd.to_numeric(self.data.get(column_name, 0), errors='coerce')\n",
        "#             return value if pd.notna(value) else 0\n",
        "#         except Exception as e:\n",
        "#             print(f\"Warning: Could not retrieve or convert '{column_name}' for {method_prefix}. Error: {e}. Defaulting to 0.\")\n",
        "#             return 0\n",
        "\n",
        "#     def get_pills_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes stock metrics for all types of Pills (Combined, Emergency, Progestin only).\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A dictionary containing metrics for each pill type.\n",
        "#         \"\"\"\n",
        "#         pills_metrics = {}\n",
        "#         pill_types = {\n",
        "#             \"combined_oral_contraceptive\": \"Combined oral contraceptive Pills\",\n",
        "#             \"emergency_pill\": \"Emergency Pill\",\n",
        "#             \"progestin_only_pills\": \"Progestin only Pills\"\n",
        "#         }\n",
        "#         metric_suffixes = {\n",
        "#             \"stock_losses\": \"Losses\",\n",
        "#             \"stock_dispensed\": \"Issued/Dispensed\",\n",
        "#             \"stock_at_hand\": \"Ending Balanc\",\n",
        "#             \"stock_requested\": \"Quantity Needed/Requested\",\n",
        "#             \"stock_received\": \"Stock Received\"\n",
        "#         }\n",
        "\n",
        "#         for key, prefix in pill_types.items():\n",
        "#             pills_metrics[key] = {\n",
        "#                 metric_name: self._get_metric(prefix, suffix)\n",
        "#                 for metric_name, suffix in metric_suffixes.items()\n",
        "#             }\n",
        "#         return pills_metrics\n",
        "\n",
        "#     def get_condoms_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes stock metrics for all types of Condoms (Female, Male).\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A dictionary containing metrics for each condom type.\n",
        "#         \"\"\"\n",
        "#         condoms_metrics = {}\n",
        "#         condom_types = {\n",
        "#             \"female_condom\": \"Female Condom\",\n",
        "#             \"male_condom\": \"Male Condom\"\n",
        "#         }\n",
        "#         metric_suffixes = {\n",
        "#             \"stock_losses\": \"Losses\",\n",
        "#             \"stock_dispensed\": \"Issued/Dispensed\",\n",
        "#             \"stock_at_hand\": \"Ending Balanc\",\n",
        "#             \"stock_requested\": \"Quantity Needed/Requested\",\n",
        "#             \"stock_received\": \"Stock Received\"\n",
        "#         }\n",
        "\n",
        "#         for key, prefix in condom_types.items():\n",
        "#             condoms_metrics[key] = {\n",
        "#                 metric_name: self._get_metric(prefix, suffix)\n",
        "#                 for metric_name, suffix in metric_suffixes.items()\n",
        "#             }\n",
        "#         return condoms_metrics\n",
        "\n",
        "#     def get_injectables_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes stock metrics for Injectables.\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A dictionary containing metrics for Injectables.\n",
        "#         \"\"\"\n",
        "#         injectables_prefix = \"Injectables\"\n",
        "#         metric_suffixes = {\n",
        "#             \"stock_losses\": \"Losses\",\n",
        "#             \"stock_dispensed\": \"Issued/Dispensed\",\n",
        "#             \"stock_at_hand\": \"Ending Balanc\",\n",
        "#             \"stock_requested\": \"Quantity Needed/Requested\",\n",
        "#             \"stock_received\": \"Stock Received\"\n",
        "#         }\n",
        "#         return {\n",
        "#             metric_name: self._get_metric(injectables_prefix, suffix)\n",
        "#             for metric_name, suffix in metric_suffixes.items()\n",
        "#         }\n",
        "\n",
        "#     def get_implants_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes stock metrics for Implants.\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A dictionary containing metrics for Implants.\n",
        "#         \"\"\"\n",
        "#         implants_prefix = \"Implants (1-Rod)\"\n",
        "#         metric_suffixes = {\n",
        "#             \"stock_losses\": \"Losses\",\n",
        "#             \"stock_dispensed\": \"Issued/Dispensed\",\n",
        "#             \"stock_at_hand\": \"Ending Balanc\",\n",
        "#             \"stock_requested\": \"Quantity Needed/Requested\",\n",
        "#             \"stock_received\": \"Stock Received\"\n",
        "#         }\n",
        "#         return {\n",
        "#             metric_name: self._get_metric(implants_prefix, suffix)\n",
        "#             for metric_name, suffix in metric_suffixes.items()\n",
        "#         }\n",
        "\n",
        "#     def get_iud_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes stock metrics for IUD.\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A dictionary containing metrics for IUD.\n",
        "#         \"\"\"\n",
        "#         iud_prefix = \"IUCD Copper T\"\n",
        "#         metric_suffixes = {\n",
        "#             \"stock_losses\": \"Losses\",\n",
        "#             \"stock_dispensed\": \"Issued/Dispensed\",\n",
        "#             \"stock_at_hand\": \"Ending Balanc\",\n",
        "#             \"stock_requested\": \"Quantity Needed/Requested\",\n",
        "#             \"stock_received\": \"Stock Received\"\n",
        "#         }\n",
        "#         return {\n",
        "#             metric_name: self._get_metric(iud_prefix, suffix)\n",
        "#             for metric_name, suffix in metric_suffixes.items()\n",
        "#         }\n",
        "\n",
        "#     def get_all_fp_metrics(self):\n",
        "#         \"\"\"\n",
        "#         Computes all available family planning metrics.\n",
        "\n",
        "#         Returns:\n",
        "#             dict: A nested dictionary containing metrics for all FP methods.\n",
        "#         \"\"\"\n",
        "#         all_metrics = {\n",
        "#             \"pills\": self.get_pills_metrics(),\n",
        "#             \"condoms\": self.get_condoms_metrics(),\n",
        "#             \"injectables\": self.get_injectables_metrics(),\n",
        "#             \"implants\": self.get_implants_metrics(),\n",
        "#             \"iud\": self.get_iud_metrics()\n",
        "#         }\n",
        "#         return all_metrics\n",
        "\n",
        "# def flatten_dict(d, parent_key='', sep='_'):\n",
        "#     \"\"\"\n",
        "#     Flattens a nested dictionary.\n",
        "\n",
        "#     Args:\n",
        "#         d (dict): The dictionary to flatten.\n",
        "#         parent_key (str): The base key for the current level of recursion.\n",
        "#         sep (str): The separator to use for concatenating keys.\n",
        "\n",
        "#     Returns:\n",
        "#         dict: A flattened dictionary.\n",
        "#     \"\"\"\n",
        "#     items = []\n",
        "#     for k, v in d.items():\n",
        "#         new_key = parent_key + sep + k if parent_key else k\n",
        "#         if isinstance(v, dict):\n",
        "#             items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
        "#         else:\n",
        "#             items.append((new_key, v))\n",
        "#     return dict(items)\n",
        "\n",
        "\n",
        "# # --- Example Usage with a Pandas DataFrame ---\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Load your data into 'data_df'\n",
        "#     # Make sure 'ke_fp_commodity_data.csv' is in the same directory or provide the full path.\n",
        "#     try:\n",
        "#         data_df = pd.read_csv('ke_fp_commodity_data.csv')\n",
        "#         print(\"Successfully loaded 'ke_fp_commodity_data.csv' into data_df.\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(\"Error: 'ke_fp_commodity_data.csv' not found.\")\n",
        "#         print(\"Please ensure the CSV file is in the correct directory or provide the full path.\")\n",
        "#         # Create an empty DataFrame to prevent further errors in the example usage\n",
        "#         data_df = pd.DataFrame()\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred while loading the CSV: {e}\")\n",
        "#         data_df = pd.DataFrame() # Ensure data_df is defined even on other errors\n",
        "\n",
        "#     if not data_df.empty:\n",
        "#         print(\"--- Original DataFrame Head ---\")\n",
        "#         print(data_df.head())\n",
        "\n",
        "#         # List to hold flattened metrics for each row\n",
        "#         all_flattened_metrics = []\n",
        "\n",
        "#         # Iterate through rows, compute metrics, and flatten them\n",
        "#         print(\"\\n--- Computing and flattening FP metrics for each row ---\")\n",
        "#         for index, row in data_df.iterrows():\n",
        "#             analyzer = FPDataAnalyzer(row)\n",
        "#             metrics = analyzer.get_all_fp_metrics()\n",
        "#             flattened = flatten_dict(metrics)\n",
        "#             all_flattened_metrics.append(flattened)\n",
        "\n",
        "#         # Create a new DataFrame from the list of flattened metrics\n",
        "#         metrics_df = pd.DataFrame(all_flattened_metrics)\n",
        "\n",
        "#         # Concatenate the original DataFrame with the new metrics DataFrame\n",
        "#         # This adds the flattened metrics as new columns to data_df\n",
        "#         data_df = pd.concat([data_df, metrics_df], axis=1)\n",
        "\n",
        "#         print(\"\\n--- DataFrame with new FP metrics columns (Head) ---\")\n",
        "#         # Display the head of the modified DataFrame, showing the new columns\n",
        "#         print(data_df.head())\n",
        "\n",
        "#         # You can now access the new columns directly, for example:\n",
        "#         # print(data_df['pills_combined_oral_contraceptive_stock_losses'].head())\n",
        "#         # print(data_df['injectables_stock_at_hand'].head())\n",
        "\n",
        "#     else:\n",
        "#         print(\"\\nDataFrame is empty. Cannot proceed with analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "YCummcVGcL2q",
        "outputId": "0e4de9fe-7c02-42f4-8257-807607af5eb5"
      },
      "outputs": [],
      "source": [
        "data_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm-5_QKachCc",
        "outputId": "78cd1682-463c-4aae-e8dc-852048bebc59"
      },
      "outputs": [],
      "source": [
        "data_df.columns\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
